{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Figure out how to deal with self intersecting cells\n",
    "- Implement odor gradient control\n",
    "- Use a different library for faster animation (maybe raylib or pygame, opensim)\n",
    "- 3D extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "import hydrostat_arm as ha\n",
    "import draw_nodes\n",
    "import obstacle\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assumptions\n",
    "1. Every cell maintains a constant volume/area. \n",
    "2. Cell edges are not springs, but they are dampers.\n",
    "3. Muscles may pull, but not push.\n",
    "4. The base of the arm has pinned boundary conditions for the bottom vertices.\n",
    "\n",
    "The cell dynamics follow the following model.\n",
    "$$\n",
    "\\ddot{q} = M^{-1} (F_e + F_i + \\hat F - B\\dot q - \\beta (q, \\dot q)) \\\\\n",
    "\\begin{align*}\n",
    "\\text{subject to } &V = V_0 \\\\\n",
    "& F_i \\ge 0 \\\\\n",
    "& \\dot q_\\text{base} = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where $q$ is the $x, y$ position of each vertex, $M$ is a diagonal matrix of vertex masses, $F_e$ are external forces acting on vertices (user defined or collisions), $F_i$ are internal forces generated by muscle activation, $\\hat F$ are reaction forces generated by the constant volume constraint, $B$ is a diagonal matrix of damping coefficients for the vertices (viscosity), $\\beta$ are linear damping forces from edge contraction/extension, and $V$ and $V_0$ are the current and initial cell volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ha)\n",
    "importlib.reload(draw_nodes)\n",
    "\n",
    "def straight_arm_maker(height):\n",
    "    vertices = [[0, 0], [1, 0]]\n",
    "    for idx in range(height):\n",
    "        vertices.append([0, (idx+1)*1])\n",
    "        vertices.append([1, (idx+1)*1])\n",
    "    vertex_indices = np.arange(len(vertices))\n",
    "    cells = np.array([[i, j, k] for i, j, k in zip(vertex_indices[:-2], vertex_indices[1:-1], vertex_indices[2:])])\n",
    "    return np.array(vertices), cells\n",
    "\n",
    "vertices, cells = straight_arm_maker(10)\n",
    "vertices = np.array([[0,0], [1, 0], [1, 1]])\n",
    "cells = np.array([[0, 1, 2]])\n",
    "# dofs = {0: [1, 0], 1: [0, 0], 2:[1, 0]}\n",
    "# arm = ha.HydrostatArm(vertices, cells, dofs)\n",
    "arm = ha.HydrostatArm(vertices, cells)\n",
    "\n",
    "def odor(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    food_loc = np.array([10, 10])\n",
    "    covar = np.eye(2)*10\n",
    "    offset = np.array([[x - food_loc[0], y - food_loc[1]]]).T\n",
    "    product = (offset.swapaxes(-2, -1) @ np.linalg.inv(covar) @ offset).T\n",
    "    return np.exp(-0.5 * np.squeeze(product))# / ((2*np.pi)**2 * np.linalg.det(covar))**0.5\n",
    "\n",
    "# arm.odor_func = odor\n",
    "\n",
    "obstacle_vertices = np.array([\n",
    "    [2, 7],\n",
    "    [2, 0],\n",
    "    [5, 0],\n",
    "    [5, 7],\n",
    "    [3.5, 8]\n",
    "])\n",
    "obst = obstacle.ConvexObstacle(obstacle_vertices)\n",
    "arm.add_obstacle(obst)\n",
    "\n",
    "obstacle_vertices = np.array([\n",
    "    [2, 16],\n",
    "    [2, 11],\n",
    "    [3.5, 10],\n",
    "    [5, 11],\n",
    "    [5, 16]\n",
    "])\n",
    "obst = obstacle.ConvexObstacle(obstacle_vertices)\n",
    "arm.add_obstacle(obst)\n",
    "\n",
    "\n",
    "drawer = draw_nodes.NodeDrawer(arm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arm.cell_volume(arm.vertices[arm.cells[-1]]))\n",
    "\n",
    "print(np.max(arm.errors))\n",
    "print(np.max(arm.errors[-1]))\n",
    "print(arm.constraints().shape)\n",
    "print(arm.jacobian_derivative().shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit Example\n",
    "\n",
    "The below sections display an example of the hydrostatic arm calculations more procedurally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Constrained Optimization with inequality constraints\n",
    "\n",
    "simulation_steps = 2000\n",
    "dt = 0.01\n",
    "t = np.arange(0, (simulation_steps+1) * dt, dt)\n",
    "\n",
    "dim = 2\n",
    "q0 = np.array([0, 0, 1, 0, 0, 1, 1, 1])\n",
    "num_nodes = len(q0)//dim\n",
    "dq0 = np.zeros(num_nodes * dim)\n",
    "M = np.diag(np.ones(num_nodes * dim))\n",
    "W = np.linalg.inv(M)\n",
    "B = np.diag(np.ones(num_nodes * dim))\n",
    "Q = np.zeros((simulation_steps, num_nodes*dim))\n",
    "Q[:len(Q)//2,4] = np.ones((simulation_steps//2))/2\n",
    "Q[len(Q)//2:,4] = -np.ones((simulation_steps//2))/2\n",
    "F = np.zeros((simulation_steps, 5))\n",
    "ks = 100\n",
    "kd = 10\n",
    "\n",
    "def cell_volume(q):\n",
    "    return 0.5 * ((q[2] - q[0]) * (q[5] - q[1]) - (q[3] - q[1]) * (q[4] - q[0]))\n",
    "\n",
    "wall = 1.5\n",
    "def C(q):\n",
    "    \"\"\"Returns an mx1 numpy array of constraints. Each constraint is set equal\n",
    "    to zero.\"\"\"\n",
    "    if q[6] >= wall:\n",
    "        return np.array([\n",
    "        cell_volume(q[0:6]) - cell_volume(q0[0:6]),\n",
    "        q[0],\n",
    "        q[1],\n",
    "        cell_volume(q[2:8]) - cell_volume(q0[2:8]),\n",
    "        q[6] - wall\n",
    "        ])\n",
    "    return np.array([\n",
    "        cell_volume(q[0:6]) - cell_volume(q0[0:6]),\n",
    "        q[0],\n",
    "        q[1],\n",
    "        cell_volume(q[2:8]) - cell_volume(q0[2:8]),\n",
    "    ])\n",
    "\n",
    "def jacobian(q):\n",
    "    \"\"\"Returns an m x n jacobian where m is the number of constraints and n is\n",
    "    the length of the state vector. Each element is the partial derivative\n",
    "    pC_i/pq_j\"\"\"\n",
    "    if q[6] >= wall:\n",
    "        return np.array([[\n",
    "            0.5*(q[3] - q[5]),\n",
    "            0.5*(q[4] - q[2]),\n",
    "            0.5*(q[5] - q[1]),\n",
    "            0.5*(q[0] - q[4]),\n",
    "            0.5*(q[1] - q[3]),\n",
    "            0.5*(q[2] - q[0]),\n",
    "            0, 0],\n",
    "\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 0, 0],\n",
    "            \n",
    "            [0, 0,\n",
    "            0.5*(q[5] - q[7]),\n",
    "            0.5*(q[6] - q[4]),\n",
    "            0.5*(q[7] - q[3]),\n",
    "            0.5*(q[2] - q[6]),\n",
    "            0.5*(q[3] - q[5]),\n",
    "            0.5*(q[4] - q[2])],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "            ])\n",
    "    return np.array([[\n",
    "        0.5*(q[3] - q[5]),\n",
    "        0.5*(q[4] - q[2]),\n",
    "        0.5*(q[5] - q[1]),\n",
    "        0.5*(q[0] - q[4]),\n",
    "        0.5*(q[1] - q[3]),\n",
    "        0.5*(q[2] - q[0]),\n",
    "        0, 0],\n",
    "\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        \n",
    "        [0, 0,\n",
    "        0.5*(q[5] - q[7]),\n",
    "        0.5*(q[6] - q[4]),\n",
    "        0.5*(q[7] - q[3]),\n",
    "        0.5*(q[2] - q[6]),\n",
    "        0.5*(q[3] - q[5]),\n",
    "        0.5*(q[4] - q[2])],\n",
    "        ])\n",
    "\n",
    "def dJ(q, dq):\n",
    "    \"\"\"Returns an m x n matrix of derivatives dJ/dt. This would technically be\n",
    "    a rank 3 tensor, but can be represented by the mxn p(pC/pq dq/dt)/pq\"\"\"\n",
    "    if q[6] >= wall:\n",
    "        return np.array([[\n",
    "            0.5*(dq[3] - dq[5]),\n",
    "            0.5*(dq[4] - dq[2]),\n",
    "            0.5*(dq[5] - dq[1]),\n",
    "            0.5*(dq[0] - dq[4]),\n",
    "            0.5*(dq[1] - dq[3]),\n",
    "            0.5*(dq[2] - dq[0]),\n",
    "            0, 0],\n",
    "\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "\n",
    "            [0, 0,\n",
    "            0.5*(dq[5] - dq[7]),\n",
    "            0.5*(dq[6] - dq[4]),\n",
    "            0.5*(dq[7] - dq[3]),\n",
    "            0.5*(dq[2] - dq[6]),\n",
    "            0.5*(dq[3] - dq[5]),\n",
    "            0.5*(dq[4] - dq[2])],\n",
    "\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        ])\n",
    "    return np.array([[\n",
    "        0.5*(dq[3] - dq[5]),\n",
    "        0.5*(dq[4] - dq[2]),\n",
    "        0.5*(dq[5] - dq[1]),\n",
    "        0.5*(dq[0] - dq[4]),\n",
    "        0.5*(dq[1] - dq[3]),\n",
    "        0.5*(dq[2] - dq[0]),\n",
    "        0, 0],\n",
    "\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "\n",
    "        [0, 0,\n",
    "        0.5*(dq[5] - dq[7]),\n",
    "        0.5*(dq[6] - dq[4]),\n",
    "        0.5*(dq[7] - dq[3]),\n",
    "        0.5*(dq[2] - dq[6]),\n",
    "        0.5*(dq[3] - dq[5]),\n",
    "        0.5*(dq[4] - dq[2])],\n",
    "    ])\n",
    "\n",
    "qs = np.empty((simulation_steps+1, num_nodes*dim))\n",
    "dqs = np.empty((simulation_steps+1, num_nodes*dim))\n",
    "qs[0] = q0\n",
    "dqs[0] = dq0\n",
    "\n",
    "for idx in range(simulation_steps):\n",
    "    q = qs[idx]\n",
    "    dq = dqs[idx]\n",
    "    J = jacobian(q)\n",
    "    lagrange_mult = (\n",
    "        np.linalg.inv(J @ W @ J.T)\n",
    "        @ ((J @ W @ B - dJ(q, dq)) @ dq - J @ W @ Q[idx] - ks * C(q) - kd * J @ dq)\n",
    "    )\n",
    "\n",
    "\n",
    "    reactions = J.T @ lagrange_mult\n",
    "    ddq = W @ (Q[idx] + reactions - B @ dq)\n",
    "    dqs[idx+1] = dq + ddq * dt\n",
    "    qs[idx+1] = q + dq * dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "def get_triangle_coords(q):\n",
    "    return ([q[0], q[2], q[4], q[0]], [q[1], q[3], q[5], q[1]])\n",
    "\n",
    "def get_net_coords(q):\n",
    "    return ([q[0], q[2], q[4], q[0], q[4], q[6], q[2]], [q[1], q[3], q[5], q[1], q[5], q[7], q[3]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axvline(1.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim([-5, 5])\n",
    "ax.set_ylim([-5, 5])\n",
    "# tri, = ax.plot(*get_triangle_coords(qs[0]))\n",
    "net, = ax.plot(*get_net_coords(qs[0]))\n",
    "arrow = ax.arrow(qs[0,4], qs[0,5], Q[0,4], Q[0,5], length_includes_head=True, head_width=.1)\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    # tri.set_data(*get_triangle_coords(qs[frame]))\n",
    "    net.set_data(*get_net_coords(qs[frame]))\n",
    "    arrow.set_data(x=qs[frame, 4], y=qs[frame, 5], dx=Q[frame, 4], dy=Q[frame,5])\n",
    "    return net, arrow,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=simulation_steps, interval=int(dt*1000))\n",
    "# ani.save('triangle_animation.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generalize the hydrostat model for cells that are not simplices (not triangles, tetrahedrons, etc) and for 3D polytopes, it is necessary to define general volume constraints, facet constraints (planar points must remain planar), and self intersection constraints (vertices going through arm edges). \n",
    "\n",
    "## General volume calculation\n",
    "There are three proposed methods of calculating the volume constraint.\n",
    "1. Use the Qhull methods via scipy wrapper. Pros: out of the box way to calculate volume. Cons: unable to update point coordinates, so new objects must be created for each cell at each time step. Probably slow. Also, not easily differentiable for calculating the Jacobian.\n",
    "2. Triangulate the shape into simplices, calculate each individual tetrahedron, and then sum the volumes. Pros: Triangulation can be done once at initialization and the point sets stored for iterating. Caclulating the volume of tetrahedrons is simple. Number of calculations scales linearly with the number of vertices. Cons: Need to figure out how to break into simplices.\n",
    "3. Break the solid into pyramids, calculate the volume of each pyramid, and then sum the volumes. Pros: Point sets can be determined at initialization. Calculations scale a little less than linearly with the number of vertices since only the area calculations would scale with vertices. Volume calculations would scale with facets. Cons: Not entirely sure how the differentiating the dot product necessary in this calculation would work. \n",
    "\n",
    "## Facet Constraints\n",
    "Certain points would need to stay on the same facet. This can be done by specifying that the volume of the facet must be zero. Then one of the three methods listed in the volume calculation section can be used.\n",
    "\n",
    "Could also calculate if relative vectors to a single point are all orthogonal to the face's normal vector.\n",
    "\n",
    "## Self Intersection\n",
    "In order to prevent vertices from going through edges, we can add half-space constraints for each vertex and edge pair. This is rather coputationally expensive but maybe it's okay? Grows at V x E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydrostat_arm_3d\n",
    "import importlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import polytopes\n",
    "\n",
    "importlib.reload(hydrostat_arm_3d)\n",
    "importlib.reload(polytopes)\n",
    "\n",
    "cube_arm = polytopes.CubeArm()\n",
    "# points = polytopes.Cube.points\n",
    "# vertices = polytopes.Cube.vertices\n",
    "# edges = polytopes.Cube.edges\n",
    "# faces = polytopes.Cube.faces\n",
    "\n",
    "cells = []\n",
    "for idx, cell in enumerate(cube_arm.cells):\n",
    "    if idx == 0:\n",
    "        cells.append(hydrostat_arm_3d.HydrostatCell3D(cell.vertices, cell.edges, cell.faces, fixed_indices=[0, 1, 2, 3]))\n",
    "    else:\n",
    "        cells.append(hydrostat_arm_3d.HydrostatCell3D(cell.vertices, cell.edges, cell.faces))\n",
    "arm = hydrostat_arm_3d.HydrostatArm3D(cube_arm.points, cells)\n",
    "\n",
    "food_loc = np.array([.5,.5,4])\n",
    "covar = np.eye(3)*10\n",
    "odor = lambda coord: stats.multivariate_normal.pdf(coord, food_loc, covar)\n",
    "arm.add_odor(odor)\n",
    "\n",
    "# _ = arm.set_external_forces(1, [0, 0, -1])\n",
    "# arm.set_muscle_actuations([8,9,10,11], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import draw_nodes_3d\n",
    "importlib.reload(draw_nodes_3d)\n",
    "drawer = draw_nodes_3d.NodeDrawer3D(arm, 1/30)\n",
    "drawer.main_loop(simulating = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_constraints(points, velocities, i, j):\n",
    "    \"\"\"verified for 1 point, move on to vectorization\"\"\"\n",
    "    N = len(points)\n",
    "    centroid = np.average(points, axis=0)\n",
    "    vcentroid = np.average(velocities, axis=0)\n",
    "    norm_points = points - centroid\n",
    "    unit = np.zeros((3,1))\n",
    "    unit[j] = 1\n",
    "\n",
    "    cov, dcdp, dcdt, ddcdpdt = calc_covariance_variables(norm_points, velocities, vcentroid, i, unit)\n",
    "    normal, dndp, dndt, ddndpdt = calc_normal_variables(cov, dcdp, dcdt, ddcdpdt)\n",
    "\n",
    "    constraint = norm_points @ normal\n",
    "    jacobian = (N-1) / N * unit.T @ normal + norm_points @ dndp\n",
    "    djacdt = (N-1) / N * unit.T @ dndt + (velocities - vcentroid)@dndp + norm_points @ ddndpdt\n",
    "    return constraint, jacobian, djacdt\n",
    "\n",
    "\n",
    "def calc_normal_variables(cov, dcdp, dcdt, ddcdpdt):\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    min_eigval = min(eigvals)\n",
    "    min_eigvec = eigvecs[:,np.argmin(eigvals)]\n",
    "\n",
    "    normal = min_eigvec\n",
    "    dndp = dNdp(eigvals, eigvecs, dcdp, min_eigval, min_eigvec)\n",
    "    dvdts = dVdts(eigvals, eigvecs, dcdt)\n",
    "    dldts = dLdts(eigvecs, dcdt)\n",
    "    ddndpdt = ddNdpdt(eigvals, eigvecs, dvdts, dldts, dcdp, ddcdpdt, min_eigval, min_eigvec)\n",
    "    return normal, dndp, dvdts[:,np.argmin(eigvals)], ddndpdt\n",
    "\n",
    "def dNdp(eigvals, eigvecs, dcdp, min_eigval, min_eigvec):\n",
    "    dndp = np.zeros(3)\n",
    "    for eigval, eigvec in zip(eigvals, eigvecs.T):\n",
    "        if eigval == min_eigval: continue\n",
    "        dndp += eigvec.reshape(1, -1) @ dcdp @ min_eigvec * eigvec / (min_eigval - eigval)\n",
    "    return dndp\n",
    "\n",
    "def dVdts(eigvals, eigvecs, dcdt):\n",
    "    eigval_dif = eigvals - eigvals[:,None] \n",
    "    eigval_dif = np.divide(1,eigval_dif, out=eigval_dif, where=eigval_dif!=0)\n",
    "    eig_block = (eigval_dif * (eigvecs.T @ dcdt @ eigvecs))[:,:,None] * eigvecs.T[:,None,:]\n",
    "    return np.sum(eig_block, axis=0).T # each col is vec\n",
    "\n",
    "def dLdts(eigvecs, dcdt):\n",
    "    dLdt = np.einsum(\"ij,ji->i\", eigvecs.T @ dcdt, eigvecs)\n",
    "    return dLdt\n",
    "\n",
    "\n",
    "def ddNdpdt(eigvals, eigvecs, dvdts, dldts, dcdp, ddcdpdt, min_eigval, min_eigvec):\n",
    "    ###NEED TO TAKE DERIVATIVE OF EIGENVALUE AS WELL!!!!\n",
    "    ddnormaldtdp = 0\n",
    "    for eigval, eigvec, dvdt, dldt in zip(eigvals, eigvecs.T, dvdts.T, dldts):\n",
    "        if eigval == min_eigval: continue\n",
    "        eig_dif = min_eigval - eigval\n",
    "        ddnormaldtdp += (dvdt@dcdp@min_eigvec) * eigvec / eig_dif\n",
    "        ddnormaldtdp += (eigvec@ddcdpdt@min_eigvec) * eigvec / eig_dif\n",
    "        ddnormaldtdp += (eigvec@dcdp@dvdts[:,np.argmin(eigvals)]) * eigvec / eig_dif\n",
    "        ddnormaldtdp += (eigvec@dcdp@min_eigvec) * dvdt / eig_dif\n",
    "        ddnormaldtdp += (eigvec@dcdp@min_eigvec) * eigvec * -(dldts[0] - dldt)/(eig_dif)**2\n",
    "        \n",
    "    return ddnormaldtdp\n",
    "    \n",
    "\n",
    "def calc_covariance_variables(norm_points, velocities, vcentroid, i, unit):\n",
    "    # all verified for single var\n",
    "    cov = np.cov(norm_points.T)\n",
    "    dcdp = dCdp(norm_points, i, unit)\n",
    "    dcdt = dCdt(norm_points, velocities, vcentroid)\n",
    "    ddcdpdt = ddCdpdt(velocities, vcentroid, i, unit)\n",
    "    return cov, dcdp, dcdt, ddcdpdt\n",
    "    \n",
    "\n",
    "def dCdp(norm_points, i, unit_vec):\n",
    "    \"\"\"Verified\"\"\"\n",
    "    # units = np.expand_dims(np.eye(3), (0, 2))\n",
    "    # points_tensor = np.expand_dims(norm_points, (1, 3))\n",
    "    # dCdp_single = points_tensor@units\n",
    "    # return 1/(N-1) * (dCdp_single.transpose(0, 1, 3, 2) + dCdp_single)\n",
    "    return 1/(N-1) * (unit_vec @ norm_points[i].reshape(1, -1) + norm_points[i].reshape(-1, 1) @ unit_vec.T)\n",
    "\n",
    "def dCdt(norm_points, velocities, vcentroid):\n",
    "    \"\"\"Verified\"\"\"\n",
    "    dcovdt = 0\n",
    "    for norm_point, vel in zip(norm_points, velocities):\n",
    "        mat =  (vel - vcentroid).reshape(-1,1)@(norm_point).reshape(1,-1)\n",
    "        dcovdt += mat + mat.T\n",
    "    dcovdt = dcovdt / (N-1)\n",
    "    return dcovdt\n",
    "\n",
    "def ddCdpdt(velocities, vcentroid, i, unit):\n",
    "    N = len(velocities)\n",
    "    mat = unit @ (velocities[i] - vcentroid).reshape(1,-1)\n",
    "    return 1/(N-1) * (mat + mat.T) # verified\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.001\n",
    "points = np.array([\n",
    "    [0, 0, .1],\n",
    "    [1, 0, 0],\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "points = polytopes.SquarePyramid.points[polytopes.SquarePyramid.faces[0]]\n",
    "velocities = np.zeros_like(points)\n",
    "velocities[0,2] = 1\n",
    "\n",
    "i = 3\n",
    "j = 1\n",
    "# constraints, jacobian, jacobian_derivative = calc_constraints(points, velocities, i, j)\n",
    "\n",
    "N = len(points)\n",
    "centroid = np.average(points, axis=0)\n",
    "vcentroid = np.average(velocities, axis=0)\n",
    "norm_points = points - centroid\n",
    "unit = np.zeros((3,1))\n",
    "unit[j] = 1\n",
    "cov, dcdp, dcdt, ddcdpdt = calc_covariance_variables(norm_points, velocities, vcentroid, i, unit)\n",
    "normal, dndp, dndt, ddndpdt = calc_normal_variables(cov, dcdp, dcdt, ddcdpdt)\n",
    "print(ddndpdt)\n",
    "\n",
    "# print(dndp)\n",
    "# print(ddndpdt)\n",
    "# points += velocities*dt\n",
    "\n",
    "# centroid = np.average(points, axis=0)\n",
    "# vcentroid = np.average(velocities, axis=0)\n",
    "# norm_points = points - centroid\n",
    "# unit = np.zeros((3,1))\n",
    "# unit[j] = 1\n",
    "# cov, dcdp, dcdt, ddcdpdt = calc_covariance_variables(norm_points, velocities, vcentroid, i, unit)\n",
    "# nnormal, ndndp, ndndt, nddndpdt = calc_normal_variables(cov, dcdp, dcdt, ddcdpdt)\n",
    "# print(ndndp)\n",
    "# print((ndndp - dndp)/dt)\n",
    "# print(constraints)\n",
    "# print(jacobian)\n",
    "# print(jacobian_derivative)\n",
    "\n",
    "# print()\n",
    "# points = points + velocities*dt\n",
    "# constraints, new_jacobian, jacobian_derivative = calc_constraints(points, velocities, i, j)\n",
    "# print(constraints)\n",
    "# print(new_jacobian)\n",
    "# print((new_jacobian + jacobian)/dt)\n",
    "# # usually, 2 terms are about doubled in terms of how much they affect the difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
