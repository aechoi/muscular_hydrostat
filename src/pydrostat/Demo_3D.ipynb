{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "\n",
    "from structure import hydrostat_arm_3d\n",
    "from structure import draw_nodes_3d\n",
    "from structure import polytopes\n",
    "from environment import environment\n",
    "from environment import obstacle\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Hydrostat Simulation\n",
    "\n",
    "The framework for this simulation matches that of the 2D simulation. In order to generalize the hydrostat model for cells that are not simplices (not triangles, tetrahedrons, etc) and for 3D polytopes, it is necessary to define general volume constraints, facet constraints (planar points must remain planar), and self intersection constraints (vertices going through arm edges). \n",
    "\n",
    "## General volume calculation\n",
    "There are three proposed methods of calculating the volume constraint.\n",
    "1. Use the Qhull methods via scipy wrapper. Pros: out of the box way to calculate volume. Cons: unable to update point coordinates, so new objects must be created for each cell at each time step. Probably slow. Also, not easily differentiable for calculating the Jacobian.\n",
    "2. Triangulate the shape into simplices, calculate each individual tetrahedron, and then sum the volumes. Pros: Triangulation can be done once at initialization and the point sets stored for iterating. Caclulating the volume of tetrahedrons is simple. Number of calculations scales linearly with the number of vertices. Cons: Need to figure out how to break into simplices.\n",
    "3. Break the solid into pyramids, calculate the volume of each pyramid, and then sum the volumes. Pros: Point sets can be determined at initialization. Calculations scale a little less than linearly with the number of vertices since only the area calculations would scale with vertices. Volume calculations would scale with facets. Cons: Not entirely sure how the differentiating the dot product necessary in this calculation would work. \n",
    "\n",
    "## Facet Constraints\n",
    "Certain points would need to stay on the same facet. In our 3D case this means the points on a face must stay on some shared 2D plane. This can be done by specifying that the relative vectors to a single point are all orthogonal to the face's normal vector.\n",
    "\n",
    "## Self Intersection\n",
    "In order to prevent vertices from going through edges, we can add half-space constraints for each vertex and edge pair. This is rather coputationally expensive but maybe it's okay? Grows at V x E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(hydrostat_arm_3d)\n",
    "importlib.reload(polytopes)\n",
    "importlib.reload(obstacle)\n",
    "importlib.reload(environment)\n",
    "\n",
    "z = 6\n",
    "cube_arm = polytopes.CubeArm(height = z)\n",
    "# points = polytopes.Cube.points\n",
    "# vertices = polytopes.Cube.vertices\n",
    "# edges = polytopes.Cube.edges\n",
    "# faces = polytopes.Cube.faces\n",
    "\n",
    "cells = []\n",
    "for idx, cell in enumerate(cube_arm.cells):\n",
    "    masses = np.ones_like(cell.vertices) / len(cell.vertices)\n",
    "    # vertex_damping = np.ones_like(cell.vertices) * 0.1\n",
    "    vertex_damping = np.ones_like(cell.vertices) / len(cell.vertices)\n",
    "    if idx == 0:\n",
    "        cells.append(hydrostat_arm_3d.HydrostatCell3D(cell.vertices, cell.edges,\n",
    "                                                      cell.faces, fixed_indices=[0, 1, 2, 3], \n",
    "                                                      masses=masses, vertex_damping=vertex_damping))\n",
    "    else:\n",
    "        cells.append(hydrostat_arm_3d.HydrostatCell3D(cell.vertices, cell.edges, cell.faces, masses=masses, vertex_damping=vertex_damping))\n",
    "arm = hydrostat_arm_3d.HydrostatArm3D(cube_arm.points / np.array([1,1,1]), cells)\n",
    "# _ = arm.set_external_forces(1, [0, 0, -1])\n",
    "# arm.set_muscle_actuations([4,5,6,7], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obst = obstacle.ConvexObstacle3D(\n",
    "    vertices = (polytopes.Cube.points * np.array([1, 10, 10]) + np.array([-2.5, -1, -1])),\n",
    "    # vertices = polytopes.Cube.points,\n",
    "    edges = polytopes.Cube.edges,\n",
    "    faces = polytopes.Cube.faces\n",
    ")\n",
    "# test_points = np.array([[0,0,0],\n",
    "#                         [0.5, 0.2,0.5],\n",
    "#                         [2,2,2],\n",
    "#                         [1,1,1]])\n",
    "# print(test_points[None,[0,1,0,1]])\n",
    "# print(obst.check_intersection(test_points))\n",
    "# print(obst.nearest_point(test_points))\n",
    "\n",
    "food_array = np.array([[-4,0,z-3, 1]])\n",
    "# food_array = np.array([[-2, 0, 0, 1]])\n",
    "env = environment.Environment3D([obst], food_array, dx=.2)\n",
    "arm.set_environment(env)\n",
    "\n",
    "# arm.add_odor(food_loc, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # # with open(\"saved_environment.pkl\", \"wb\") as f:\n",
    "# # #     pickle.dump(env, f)\n",
    "# with open(\"saved_environment.pkl\", \"rb\") as f:\n",
    "#     env = pickle.load(f)\n",
    "#     arm.set_environment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(draw_nodes_3d)\n",
    "drawer = draw_nodes_3d.NodeDrawer3D(arm, dt=1/60)\n",
    "drawer.main_loop(simulating = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Demo\n",
    "The rest below are various debugging things that I need to clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize face constraints - setup\n",
    "faces = arm.faces\n",
    "# faces = faces[:2]\n",
    "\n",
    "faces = [\n",
    "    [0, 1, 2, 3],\n",
    "    [0, 4, 5, 6, 7]\n",
    "]\n",
    "\n",
    "flat_faces = []\n",
    "face_indices = []\n",
    "for face_index, face in enumerate(faces):\n",
    "    for vertex in face:\n",
    "        face_indices.append(face_index)\n",
    "        flat_faces.append(vertex)\n",
    "\n",
    "flat_faces = np.array(flat_faces)\n",
    "face_indices = np.array(face_indices)\n",
    "_, change_indices, change_counts = np.unique(face_indices, return_index=True, return_counts=True)\n",
    "change_indices = change_indices + change_counts\n",
    "\n",
    "# end preprocess\n",
    "\n",
    "positions = arm.positions\n",
    "# velocities = arm.velocities\n",
    "velocities = np.random.random(arm.positions.shape)\n",
    "points = positions[flat_faces]\n",
    "dpointsdt = velocities[flat_faces]\n",
    "\n",
    "cum_pos = np.cumsum(points, axis=0)\n",
    "pos_sums = np.diff(np.vstack((np.zeros_like(cum_pos[0]), cum_pos[change_indices-1])), axis=0)\n",
    "centroids = pos_sums/change_counts[:,None]\n",
    "centered_points = points - centroids[face_indices]\n",
    "\n",
    "cum_vel = np.cumsum(dpointsdt, axis=0)\n",
    "vel_sums = np.diff(np.vstack((np.zeros_like(cum_vel[0]), cum_vel[change_indices-1])), axis=0)\n",
    "dcentroidsdt = vel_sums/change_counts[:,None]\n",
    "centered_velocities = dpointsdt - dcentroidsdt[face_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize face constraints - covariances\n",
    "dofs = change_counts - 1\n",
    "\n",
    "block_points = np.zeros((len(centered_points), len(faces)*3))\n",
    "col_indices = np.repeat(np.arange(len(faces)*3).reshape(-1,3), change_counts, axis=0)\n",
    "row_indices = np.repeat(np.arange(len(centered_points)).reshape(-1,1), 3, axis=1)\n",
    "block_points[row_indices, col_indices] = centered_points\n",
    "covs = block_points.T @ block_points\n",
    "\n",
    "row_extract = np.repeat(np.arange(len(covs)).reshape(-1,3), 3, axis=0)\n",
    "col_extract = np.repeat(np.arange(len(covs)).reshape(-1,1), 3, axis=1)\n",
    "covs = covs[row_extract, col_extract].reshape(len(faces), 3, 3)\n",
    "\n",
    "# dCdt\n",
    "block_vels = np.zeros_like(block_points)\n",
    "block_vels[row_indices, col_indices] = centered_velocities\n",
    "dcdt_single = block_vels.T @ block_points\n",
    "dof_map = np.repeat(np.arange(len(faces)), 3)\n",
    "dcdt = (dcdt_single + dcdt_single.T) / dofs[dof_map]\n",
    "dcdt = dcdt[row_extract, col_extract].reshape(len(faces), 3, 3)\n",
    "\n",
    "# dCdP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import environment\n",
    "import obstacle\n",
    "import polytopes\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "importlib.reload(environment)\n",
    "importlib.reload(obstacle)\n",
    "\n",
    "obst = obstacle.ConvexObstacle3D(\n",
    "    vertices = (polytopes.Cube.points + np.array([-2, 0, 2])*0),\n",
    "    edges = polytopes.Cube.edges,\n",
    "    faces = polytopes.Cube.faces\n",
    ")\n",
    "\n",
    "env = environment.Environment3D([obst], np.array([[-.1, -.1, 0.5, 1]]))\n",
    "# obst_mask = obst.calc_many_intersections(env.grid.reshape(-1, 3)).reshape(100, 100, 100)\n",
    "# print(np.max(obst_mask +0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "concentration = env.concentration.reshape(-1)\n",
    "conc_mask = (concentration <= .1) * (concentration > 0.01)\n",
    "ax.scatter(*env.grid_points[conc_mask,:].T, marker=\".\")\n",
    "conc_mask = (concentration == 0)\n",
    "ax.scatter(*env.grid_points[conc_mask,:].T, marker=\".\")\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_zlim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "arm.calc_next_states(dt = 1/60)\n",
    "arm.calc_next_states(dt = 1/60)\n",
    "arm.calc_next_states(dt = 1/60)\n",
    "\n",
    "positions = arm.positions\n",
    "velocities = arm.velocities\n",
    "face_indices = arm.faces[-1]\n",
    "\n",
    "t = timeit.Timer(lambda: np.diff(arm.positions[arm.edges], axis=1).reshape(-1,3))\n",
    "print(t.timeit(1000))\n",
    "print(np.diff(arm.positions[arm.edges], axis=1).shape)\n",
    "def difference():\n",
    "    points = arm.positions[arm.edges]\n",
    "    return points[:,0] - points[:,1]\n",
    "t = timeit.Timer(lambda: difference())\n",
    "print(t.timeit(1000))\n",
    "print(difference().shape)\n",
    "\n",
    "# points = positions[face_indices]\n",
    "# dpointsdt = velocities[face_indices]\n",
    "\n",
    "# centroid = np.average(points, axis=0)\n",
    "# dcentroiddt = np.average(dpointsdt, axis=0)\n",
    "# centered_points = points - centroid\n",
    "# centered_velocities = dpointsdt - dcentroiddt\n",
    "\n",
    "# dcdt_single = np.einsum(\"ij,ik->jk\", centered_velocities, centered_points)\n",
    "# # dcdt_single = centered_velocities.T @ centered_points\n",
    "\n",
    "# t = timeit.Timer(lambda: np.einsum(\"ij,ik->jk\", centered_velocities, centered_points))\n",
    "# print(t.timeit(1000))\n",
    "\n",
    "# t = timeit.Timer(lambda: centered_velocities.T @ centered_points)\n",
    "# print(t.timeit(1000))\n",
    "# t = timeit.Timer(lambda: hydrostat_arm_3d.calc_face_constraints(positions, velocities, face_indices))\n",
    "# print(t.timeit(10000)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scent Propogation Demo\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "diffusion_coef = 1\n",
    "\n",
    "dx = 0.1\n",
    "x = np.arange(-5, 5, dx)\n",
    "y = np.arange(-5, 5, dx)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "dt = dx**2/(4*diffusion_coef) * 0.99\n",
    "final_time = 20\n",
    "t = np.arange(0, final_time, dt)\n",
    "\n",
    "concentration = np.zeros((len(t), len(x), len(x)))\n",
    "concentration[0, 50, 80] = 1\n",
    "\n",
    "convolve_pattern = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "obst_mask = np.zeros_like(concentration[0])\n",
    "# obst_mask[np.arange(40,60), 55] = 1\n",
    "# obst_mask[np.arange(40,60), 45] = 1\n",
    "# obst_mask[60, np.arange(45,55)] = 1\n",
    "\n",
    "obst_mask[np.arange(40, 60), np.arange(45, 65)] = 1\n",
    "adj_obst = sig.convolve2d(obst_mask, convolve_pattern, mode=\"same\", boundary=\"fill\")\n",
    "\n",
    "for idx, frame in enumerate(concentration):\n",
    "    if idx == 0: continue\n",
    "    concentration[idx] = concentration[idx-1] + dt*diffusion_coef*nd.laplace(concentration[idx-1], mode=\"constant\")/dx**2\n",
    "    concentration[idx, 50, 50] = 1\n",
    "    concentration[idx] += dt*diffusion_coef/dx**2 * (concentration[idx-1] * adj_obst)\n",
    "    concentration[idx] = concentration[idx] * (1-obst_mask)\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(concentration[-1])\n",
    "\n",
    "print(np.sum(concentration[-1]))\n",
    "\n",
    "# def update(frame):\n",
    "#     im.set_data(concentration[frame])\n",
    "#     im.set_clim(vmin=np.min(concentration[frame]), vmax=np.max(concentration[frame]))\n",
    "\n",
    "# ani = anim.FuncAnimation(fig, update, frames=len(concentration)-1, interval=1/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double dot\n",
    "import numpy as np\n",
    "\n",
    "T1 = np.arange(2*3*4*5).reshape(2, 3, 4, 5)\n",
    "T2 = np.arange(3*4*5*6).reshape(3, 4, 5, 6)\n",
    "overlap = 3\n",
    "\n",
    "T1 = np.arange(2*3*4*5).reshape(2, 3, 4, 5)\n",
    "T2 = np.arange(4*5*6*7).reshape(4, 5, 6, 7)\n",
    "overlap = 2\n",
    "\n",
    "T1 = np.arange(2*3*4*5).reshape(2, 3, 4, 5)\n",
    "lambdas = np.arange(2)\n",
    "print(np.tensordot(lambdas, T1, 1).shape)\n",
    "\n",
    "# a = T1.reshape(T1.shape[:-overlap] + (-1,))\n",
    "# b = T2.reshape((-1,) + T2.shape[overlap:]).swapaxes(0, -2)\n",
    "# print(a.shape)\n",
    "# print(b.shape)\n",
    "# print(a@b)\n",
    "# t = timeit.Timer(lambda: (T1.reshape(T1.shape[:-overlap]+(-1,)) @ T2.reshape((-1,) + T2.shape[overlap:]).swapaxes(0, -2)).reshape(T1.shape[:-overlap] + T2.shape[overlap:]))\n",
    "# print(t.timeit(1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
